# $\fbox{Chapter 1: INTRODUCTION}$





## **Topic - 1: Introduction To Data**

### <u>Data</u>

- **<u>Data</u>:** Any kind of figure/quantity/symbols stored on storage devices.


### <u>Types Of Data</u>

1. **<u>Quantitative data</u>:** Numerical data
2. **<u>Qualitative data</u>:** Descriptive data

#### Quantitative data:

1. **<u>Discrete data</u>:** Countable data
2. **<u>Continuous data</u>:** Measurable data



## **Topic - 2: Introduction To Big Data**

### <u>Introduction</u>

- **<u>Big data</u>:** Data which together occupy size in petabytes (PBs).

>**<u>NOTE</u>:**
>$90\%$ of total data available today is generated in last $3$ years!


### <u>Sources Of Big Data</u>

- Social media
- Traffic data
- GPS signal
- Emails, blogs & articles
- Software logs
- Weather stations & satellite
- Media files on internet


### <u>Big Data Characteristics</u>

1. **<u>Volume</u>:** In petabytes (PBs).
2. **<u>Value</u>:** Using data as valuable insights for real-world application.
3. **<u>Veracity</u>:** Unpredictability & inefficiencies in available data.
4. **<u>Visualization</u>:** Representing data in any visual form.
5. **<u>Variety</u>:** Composition of various forms of data at single place.
6. **<u>Valocity</u>:** Rate of growth of data.
7. **<u>Virality</u>:** Rate of spread of data.


### <u>Variety</u>

- Variety not in just terms of heterogeneous sources but structure too.
- This also includes data from various file formats.
- One major challenge is to manipulate such a large amount of data altogether.


### <u>Veracity</u>

- Veracity can be handled if there is hygiene in data.
- Its not just about unhygienic data but also about trustworthiness of sources from where its gathered.


### <u>Velocity</u>

- New data before being analyzed, are warehoused.
- But need for real-time processing is increasing to mitigate storage shortage due to warehousing.
- Real-time processing helps in analyzing data as it comes.


### <u>Value</u>

- Value is the end goal of organizations.
- It is about generating revenue by the insights gathered through analysis of data.



## **Topic - 3: Challenges Of Conventional System**

### <u>Major Problems</u>

1. Volume of data
2. Processing & analyzing
3. Management of data


### <u>Processing & Analyzing</u>

- Taking out insights from such a large amount of data is difficult.
- Processing so much data is also very costly.


### <u>Management Of Data</u>

- Management is difficult due to the structured, semi-structured & unstructured nature of it, altogether.



## **Topic - 4: Types Of Big Data**

### <u>Unstructured</u>

- Deriving data from unstructured data is a major challenge.
- Such data could include texts, images & other media files altogether.
- For example, webpage & Google search etc.


### <u>Structured</u>

- **<u>Structured data</u>:** Any data that has fixed format.
- For example, RDBMS tables or consistent format etc.


### <u>Semi-Structured</u>

- **<u>Semi-structured data</u>:** Unrefined data from which, extracting useful information is comparatively easier.
- For example, web caches which provide critical info but are not structured enough.


### <u>Differences Comparison</u>

| Factors               | Structured Data            | Semi-Structured Data | Unstructured Data         |
| :-------------------- | :------------------------- | :------------------- | :------------------------ |
| **Dependence**        | Dependent                  | Partially dependent  | Independent               |
| **Flexibility**       | Less flexible              | Moderately flexible  | Very flexible             |
| **Transaction**       | Secured transaction        | Derived transaction  | No transaction management |
| **Concurrency**       | Used                       | Derived              | Not used                  |
| **Query performance** | Structured queries         | Immature queries     | No queries                |
| **Technology used**   | Relational database tables | RDF & XML            | Raw data library          |



## **Topic - 5: Intelligent Data Analysis (IDA)**

### <u>Introduction</u>

- IDA is related to artificial intelligence.
- It is about digging previously unknown insights from large amount of data.
- Fields using it - Data engineering, database mining, and many more.
- **Rule finding** is finding for rules in dataset for existing data.
- These usually use ML & deep learning methods.


### <u>Steps For IDA</u>

1. Data preparation
2. Rules finding or data mining
3. Result validation & explanation



## **Topic - 6: Traditional v/s Business Approach**

### <u>Traditional Data v/s Big Data</u>

| Traditional Data                                         | Big Data                                                             |
| :------------------------------------------------------- | :------------------------------------------------------------------- |
| Generated at enterprise level.                           | Generated outside & used at enterprise level.                        |
| Volume ranges from GBs to TBs.                           | Volume ranges from PBs to EBs (exabytes).                            |
| Deals only with structured data.                         | Deals with both structured & unstructured data.                      |
| Generated less frequently.                               | Generated more frequently.                                           |
| Data is centralized.                                     | Data is distributed.                                                 |
| Data integration is easy.                                | Data integration is very difficult.                                  |
| Default system configuration is enough to process it.    | Specialized & more powerful configuration is required to process it. |
| General purpose database tools are enough to operate it. | Requires special tools to operate it.                                |
| Needs common algorithms to perform operations on it.     | Needs special algorithms to perform operations on it.                |
| Data model is schema-based & thus strict.                | Data model is not schema-based & thus flexible.                      |
| Stable & inter-related.                                  | Unstable & not necessarily inter-related.                            |
| For example - Financial records, web transactions etc.   | For example - Video, social media etc.                               |


### <u>Confidentiality & Data Accuracy</u>

- **<u>Confidentiality</u>:** Setting up rules & restrictions to limit access to confidential data.
- This is dealt with access control & cryptography.
